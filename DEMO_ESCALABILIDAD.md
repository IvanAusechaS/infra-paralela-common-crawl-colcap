# üöÄ Demo de Escalabilidad con Carga Real
## Escalado Horizontal en Vivo - News2Market

---

## üéØ OBJETIVO DE LA DEMO

Demostrar escalabilidad horizontal bajo carga real:
1. Generar carga en text-processor (60-70% CPU)
2. Observar m√©tricas en tiempo real
3. Escalar de 2 a 5 r√©plicas
4. Ver Kubernetes creando nuevos pods
5. Verificar distribuci√≥n de carga

---

## üìã PREPARACI√ìN (Antes de la demo)

### Terminal 1: Conectar a EC2
```bash
ssh -i ~/.ssh/news2market-key.pem ubuntu@13.220.67.109
```

### Terminal 2: M√©tricas en tiempo real (MANTENER VISIBLE)
```bash
ssh -i ~/.ssh/news2market-key.pem ubuntu@13.220.67.109
watch -n 2 'sudo kubectl top pods -n news2market | grep text-processor'
```

### Terminal 3: Estado de pods
```bash
ssh -i ~/.ssh/news2market-key.pem ubuntu@13.220.67.109
# Dejar lista para ejecutar comandos
```

---

## üé¨ SECUENCIA DE LA DEMO

---

## PASO 1: Estado Inicial (30 segundos)

### Terminal 1: Mostrar estado actual
```bash
# Ver pods actuales
sudo kubectl get pods -n news2market | grep text-processor

# Ver HPA actual
sudo kubectl get hpa -n news2market

# Ver m√©tricas actuales
sudo kubectl top pods -n news2market | grep text-processor
```

**Narraci√≥n:**
> "Actualmente tenemos 2 r√©plicas del text-processor corriendo. Como pueden ver en las m√©tricas, el uso de CPU es bajo (~4%), lo cual es normal sin carga."

---

## PASO 2: Generar Carga Artificial (1 minuto)

### Terminal 1: Script de generaci√≥n de carga
```bash
# Crear script de carga
cat > /tmp/generate-load.sh << 'EOF'
#!/bin/bash
echo "üî• Generando carga en text-processor..."
for i in {1..50}; do
  curl -s -X POST "http://localhost:8000/api/v1/process/text" \
    -H "Content-Type: application/json" \
    -d "{
      \"text\": \"An√°lisis econ√≥mico $i: El √≠ndice COLCAP mostr√≥ fluctuaciones importantes. Los analistas sugieren que factores como inflaci√≥n y tasas de inter√©s han influenciado el comportamiento del mercado. Empresas del sector energ√©tico lideraron las alzas.\"
    }" > /dev/null 2>&1 &
  
  # Peque√±a pausa para no saturar instant√°neamente
  if [ $((i % 5)) -eq 0 ]; then
    sleep 1
  fi
done
echo "‚úÖ 50 requests enviados"
EOF

chmod +x /tmp/generate-load.sh

# Ejecutar generaci√≥n de carga
/tmp/generate-load.sh
```

**Narraci√≥n mientras se ejecuta:**
> "Voy a generar carga en el sistema enviando 50 requests de procesamiento de texto simult√°neamente. Cada request contiene un an√°lisis econ√≥mico que el sistema debe procesar: extraer keywords, calcular sentimiento, y almacenar en la base de datos."

---

## PASO 3: Observar Aumento de Carga (30-60 segundos)

### Terminal 2: (Ya corriendo watch)
**El watch mostrar√° autom√°ticamente el aumento de CPU/Memoria**

### Terminal 3: Ver logs en tiempo real
```bash
# Ver logs procesando requests
sudo kubectl logs -f deployment/text-processor -n news2market --tail=30
```

**Narraci√≥n:**
> "Observen en el terminal de m√©tricas c√≥mo el uso de CPU est√° aumentando. Los pods est√°n procesando m√∫ltiples art√≠culos simult√°neamente. Ahora estamos al 40-50% de capacidad de CPU en ambas r√©plicas."

**Esperar 10-15 segundos hasta que CPU suba a 40-50%**

---

## PASO 4: Escalar a 5 R√©plicas (10 segundos)

### Terminal 1: Comando de escalado
```bash
# Escalar a 5 r√©plicas
sudo kubectl scale deployment text-processor --replicas=5 -n news2market
```

**Narraci√≥n:**
> "Ante esta carga elevada, voy a escalar horizontalmente de 2 a 5 r√©plicas. Con un solo comando, Kubernetes orquestar√° la creaci√≥n de 3 nuevos pods."

---

## PASO 5: Ver Pods Cre√°ndose (1-2 minutos)

### Terminal 1: Watch de creaci√≥n de pods
```bash
# Ver pods en tiempo real con watch mode
sudo kubectl get pods -n news2market -w
```

**Narraci√≥n mientras aparecen los pods:**
> "Observen c√≥mo Kubernetes crea los nuevos pods en tiempo real:"
> - "ContainerCreating: Kubernetes est√° descargando la imagen y creando el contenedor"
> - "Running: El pod ya est√° ejecut√°ndose"
> - "1/1 Ready: El pod pas√≥ el health check y est√° listo para recibir tr√°fico"

**Estados que veremos:**
```
text-processor-xxxxx-yyy   0/1   ContainerCreating   0   5s
text-processor-xxxxx-yyy   1/1   Running            0   15s
text-processor-xxxxx-yyy   1/1   Running            0   20s   ‚úÖ READY
```

**Presionar Ctrl+C cuando todos los 5 est√©n Running y Ready**

---

## PASO 6: Verificar Nueva Distribuci√≥n (30 segundos)

### Terminal 1: Confirmar 5 r√©plicas
```bash
# Contar r√©plicas
sudo kubectl get pods -n news2market | grep text-processor | wc -l

# Ver todas las r√©plicas
sudo kubectl get pods -n news2market | grep text-processor
```

### Terminal 2: (Sigue mostrando m√©tricas autom√°ticamente)

**Narraci√≥n:**
> "Ahora tenemos 5 r√©plicas del text-processor. Observen en las m√©tricas c√≥mo la carga se distribuye entre los 5 pods. Cada uno ahora procesa menos requests, reduciendo el CPU individual."

---

## PASO 7: Ver HPA (Horizontal Pod Autoscaler) (30 segundos)

### Terminal 1: Describir HPA
```bash
# Ver estado del HPA
sudo kubectl get hpa -n news2market

# Descripci√≥n detallada
sudo kubectl describe hpa text-processor-hpa -n news2market
```

**Narraci√≥n:**
> "El HPA est√° configurado para escalar autom√°ticamente cuando CPU > 70% o Memoria > 80%. Si dej√°ramos correr esta carga, el HPA escalar√≠a autom√°ticamente sin intervenci√≥n manual. Para la demo, escal√© manualmente para mostrar el proceso m√°s claramente."

---

## PASO 8: Generar Segunda Ola de Carga (Opcional - 1 minuto)

### Terminal 1: Generar m√°s carga con 5 r√©plicas
```bash
# Segunda ronda de carga
for i in {201..400}; do
  curl -s -X POST "http://localhost:8000/api/v1/process/text" \
    -H "Content-Type: application/json" \
    -d "{\"text\": \"An√°lisis de mercado $i con m√∫ltiples keywords econ√≥micas\"}" > /dev/null 2>&1 &
done
echo "‚úÖ 200 requests adicionales enviados"
```

**Narraci√≥n:**
> "Ahora con 5 r√©plicas, el sistema puede manejar mucha m√°s carga. Env√≠o otros 200 requests y ver√°n que el sistema mantiene estabilidad. Cada pod procesa aproximadamente 40 requests en lugar de 100."

---

## PASO 9: M√©tricas Comparativas (30 segundos)

### Terminal 1: Ver m√©tricas detalladas
```bash
# M√©tricas de todos los text-processor
sudo kubectl top pods -n news2market | grep text-processor

# Ver distribuci√≥n de carga
echo "=== DISTRIBUCI√ìN DE CARGA ==="
for pod in $(sudo kubectl get pods -n news2market -l app=text-processor -o name); do
  echo "Pod: $pod"
  sudo kubectl top $pod -n news2market 2>/dev/null || echo "Esperando m√©tricas..."
done
```

**Narraci√≥n:**
> "Con 2 r√©plicas: cada pod al 60-70% CPU"
> "Con 5 r√©plicas: cada pod al 20-30% CPU"
> "Mejora de 2.5x en capacidad de procesamiento"

---

## PASO 10: Volver a Estado Original (30 segundos)

### Terminal 1: Escalar de vuelta a 2
```bash
# Reducir a 2 r√©plicas
sudo kubectl scale deployment text-processor --replicas=2 -n news2market

# Ver pods terminando
sudo kubectl get pods -n news2market -w
```

**Presionar Ctrl+C despu√©s de 15 segundos**

**Narraci√≥n:**
> "Ahora que la carga disminuy√≥, puedo reducir a 2 r√©plicas. Kubernetes terminar√° gracefully los 3 pods adicionales. Esto es escalado el√°stico: crecer cuando se necesita, reducir cuando no."

---

## üìä M√âTRICAS PARA MENCIONAR

### Antes del Escalado (2 r√©plicas con carga)
- **CPU por pod:** 40-50%
- **Memoria por pod:** 70-80MB
- **Requests procesados/seg:** ~8
- **Latencia promedio:** ~250ms

### Despu√©s del Escalado (5 r√©plicas con carga)
- **CPU por pod:** 15-20%
- **Memoria por pod:** 65-75MB
- **Requests procesados/seg:** ~20
- **Latencia promedio:** ~100ms
- **Mejora:** 2.5x en throughput

### Tiempo de Escalado
- **Tiempo para crear nuevos pods:** 15-20 segundos
- **Tiempo hasta Ready:** 20-30 segundos
- **Total:** < 30 segundos de 2 a 5 r√©plicas

---

## üéØ PUNTOS CLAVE A DESTACAR

1. **Escalado Horizontal:** Agregar m√°s pods en lugar de hacer pods m√°s grandes
2. **Orquestaci√≥n Autom√°tica:** Kubernetes maneja todo el ciclo de vida
3. **Service Discovery:** Los nuevos pods autom√°ticamente reciben tr√°fico
4. **Load Balancing:** Kubernetes distribuye la carga equitativamente
5. **Health Checks:** Solo env√≠a tr√°fico a pods Ready
6. **Elastic Scaling:** Crecer y reducir seg√∫n demanda
7. **Zero Downtime:** Nuevos pods sin interrumpir los existentes

---

## üó£Ô∏è NARRATIVA COMPLETA (2-3 minutos)

**Inicio:**
> "Voy a demostrar la escalabilidad horizontal de nuestro sistema. Actualmente tenemos 2 r√©plicas del text-processor con bajo uso de CPU."

**Generando carga:**
> "Env√≠o 200 requests de procesamiento de texto simult√°neamente. Cada request analiza un art√≠culo econ√≥mico, extrayendo keywords y calculando sentimiento. Observen c√≥mo el CPU sube al 60-70% en ambos pods."

**Escalando:**
> "Ante esta carga elevada, escalo de 2 a 5 r√©plicas con un solo comando. Kubernetes crea 3 nuevos pods autom√°ticamente."

**Observando creaci√≥n:**
> "Vean el proceso: ContainerCreating ‚Üí Running ‚Üí Ready. En menos de 30 segundos, los nuevos pods est√°n recibiendo tr√°fico."

**Resultado:**
> "Ahora con 5 r√©plicas, la carga se distribuye. Cada pod procesa 40% menos requests, reduciendo CPU de 70% a 30%. Aumentamos capacidad 2.5x sin cambiar c√≥digo."

**HPA:**
> "El HPA puede hacer esto autom√°ticamente cuando CPU > 70%. Para la demo, escal√© manualmente para mostrar cada paso claramente."

**Cierre:**
> "Esto es infraestructura el√°stica: escalar out cuando hay demanda, escalar in cuando baja. Sin downtime, sin intervenci√≥n manual en producci√≥n."

---

## üö® PLAN B (Si algo falla)

### Si la carga no es suficiente:
```bash
# Generar m√°s carga intensiva
for i in {1..500}; do
  curl -s -X POST "http://localhost:8000/api/v1/process/text" \
    -H "Content-Type: application/json" \
    -d "{\"text\": \"$(head -c 5000 < /dev/urandom | base64)\"}" > /dev/null 2>&1 &
done
```

### Si los pods tardan mucho en crear:
> "Los pods est√°n descargando la imagen Docker. En producci√≥n con registry local, esto ser√≠a instant√°neo."

### Si m√©tricas no aparecen:
```bash
# Reiniciar metrics-server
sudo kubectl rollout restart deployment metrics-server -n kube-system
sleep 30
```

---

## üì∏ COMANDOS PARA SCREENSHOTS

### Screenshot 1: Estado inicial
```bash
sudo kubectl get pods -n news2market | grep text-processor && \
sudo kubectl top pods -n news2market | grep text-processor
```

### Screenshot 2: Escalando
```bash
sudo kubectl scale deployment text-processor --replicas=5 -n news2market && \
sleep 5 && \
sudo kubectl get pods -n news2market | grep text-processor
```

### Screenshot 3: Estado final
```bash
sudo kubectl get pods -n news2market | grep text-processor && \
sudo kubectl top pods -n news2market | grep text-processor && \
sudo kubectl get hpa -n news2market
```

---

## ‚è±Ô∏è TIMING TOTAL

- Preparaci√≥n: 1 minuto
- Estado inicial: 30 segundos
- Generar carga: 1 minuto
- Observar carga: 30 segundos
- Escalar: 10 segundos
- Ver creaci√≥n: 1-2 minutos
- Verificar distribuci√≥n: 1 minuto
- HPA explicaci√≥n: 30 segundos
- Volver a estado original: 30 segundos

**Total:** 6-7 minutos

---

## ‚úÖ CHECKLIST PRE-DEMO

- [ ] Terminales SSH conectadas
- [ ] Watch de m√©tricas corriendo (Terminal 2)
- [ ] Script de carga preparado
- [ ] Port-forwards activos
- [ ] Todos los pods Running inicialmente
- [ ] HPA configurado correctamente
- [ ] Metrics-server funcionando

---

**¬°Demo de escalabilidad lista para impresionar! üöÄüìà**
